{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TE1SDLvcztik",
    "outputId": "1896ae67-3756-4a7d-da38-f3a445c6aaed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "Reconstructed Output:\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#q6\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Dataset\n",
    "sentences = [\n",
    "    \"The sky is blue\",\n",
    "    \"The sun is bright\",\n",
    "    \"The grass is green\",\n",
    "    \"The night is dark\",\n",
    "    \"The stars are shining\"\n",
    "]\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "max_len = max(len(seq) for seq in sequences)\n",
    "padded = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Simple VAE\n",
    "input_dim = max_len\n",
    "latent_dim = 2\n",
    "\n",
    "inputs = Input(shape=(input_dim,))\n",
    "h = Dense(16, activation='relu')(inputs)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "decoder_h = Dense(16, activation='relu')\n",
    "decoder_output = Dense(input_dim, activation='sigmoid')\n",
    "\n",
    "h_decoded = decoder_h(z)\n",
    "outputs = decoder_output(h_decoded)\n",
    "\n",
    "vae = Model(inputs, outputs)\n",
    "vae.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "vae.fit(padded, padded, epochs=200, verbose=0)\n",
    "\n",
    "reconstructed = vae.predict(padded)\n",
    "print(\"Reconstructed Output:\")\n",
    "print(np.round(reconstructed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737,
     "referenced_widgets": [
      "ea1f67d6e126449f99b2512ebde648df",
      "3031eb984fec4da4b7ef42a75df2efca",
      "b9185e066328406980f12a3cf4f344f9",
      "039ab89aeaca456396aa96df83cc5e6b",
      "b230a093d49e419390b20f1b595e9393",
      "c360dbacd9f94ddc8ff0669895461fc0",
      "c4f61f742e3c4bff95cc34a9e7495946",
      "469fcd816b974b64a43289dd6b9bf79d",
      "0268cde54d2a46b98a5926912daf5885",
      "41ce3a9df53b4f809dc57da1de64eb3a",
      "b2a39d254dc944e784ebb020b3a53924",
      "35485d2019e84e75b7d3f1c29eebd4c6",
      "bd286c84ebfb42eeafd0f234632bdf5b",
      "61e060d8f6fc4b4092aa993de66fa801",
      "f7203ccbde63418b8afe4e37adb59784",
      "e0b94d0c8d9f47fc93a7339c8d0fc829",
      "60bc87dea5774e948e9fe2822b15632e",
      "c1779fa93aa2475895700e38f93e45de",
      "2d20f12f2caf48b1862f12c3cecaff76",
      "6fbd7269361b442291a2da788328cd65",
      "941e67215f0a4d329ebe228261d6c629",
      "2ee47adfcb774440aa52369ba0b76f70",
      "3d8442560da74575bed9e715da21403e",
      "649cbcd10a4b4922bf3efecb637457a8",
      "92182ba328e2405da4f1a14592a530ed",
      "802b3eb35ce844a3aab0b731d948b755",
      "bc865be174304d0491af1f6a9815dac1",
      "d1b8ba293c4d4abe8a8aeb0e4f265977",
      "bccbc398d9f24179a411fe0f2d2d5536",
      "81823991473f4d9981973f0416e2e759",
      "3716318d976745ee9cbd37abd7ab98af",
      "4fcadd85e8544304bc19a2aaa871b960",
      "1de4bb37c5ec44a0b005f6576790e576",
      "b67a38341c95494d9b0a2af64b51d1fb",
      "e8e2dc8f7af44fb1826217f270118454",
      "d84e73679e5248b8be54ec05688195f2",
      "6de772aba77847e3858f4ac0b48437fe",
      "c04830c64680451cbde9db4922f9d62d",
      "e21022d5d03b4133be29baa539301088",
      "7d9cfd03cbb04d77ba7e6cb87797bcfa",
      "395cb922c9b5495586086ad52e7c21de",
      "11eb592c06154d70a438baf7b0cd183e",
      "33b23a06f9a44981a1f9992d6df92593",
      "c72f4fec53924d0f887332ee2b51b540",
      "c88f89ce739143438323e0bb0565146d",
      "335a439ec6eb45d5a7f352d696621c87",
      "ca5e51f5c80f466f8e5822633c958590",
      "f9e6c07a198f4466876055e8fa1cc4d2",
      "4f9bfc75f3cb440faf96d0f116346b73",
      "a8a93d1c590a48a6bca8a6881a7eba21",
      "4b6cd557e3324c419ba49b85be4f3b2d",
      "e9154015866b42baad6e8d90c9bb11ce",
      "8d82de21ce0a41e5bfbbe304f0a2ddbd",
      "830f1659b3e74c89a4d484372b752f50",
      "f409e566f4e34d289893d0f5ffb7e977",
      "f0b7a469845b44ff9fab1d0e86e613ac",
      "983ef7613ed64dcea61629224cf6aff2",
      "a34fe0e7879b43909563bdb35aad4de2",
      "9ecd30dcd83a4c9f8a3d99a64e8157e4",
      "6341b106d75e46399fc12a620010ddcf",
      "d4ec3ff4eddb44ca8d67a7b8394e2a98",
      "4439859d3f1e4530a6054af592f518aa",
      "bdd92bff4f8e436683e3ad7e779302ea",
      "3dc413903daf425599348219a283c22b",
      "cb6e8e7c4e19475f92d39dab767e81fb",
      "ed5f531724e64f6fbae9fb16fde4b77b",
      "88e7befac7b2479e84733805e0bbc809",
      "cb4b1560e6964c8ba89a8a937e95d256",
      "0480a36c453e40cbb14236fa4fd506e2",
      "b764a4bd3f954ebdb4cca9dfe425ab70",
      "dcf2ec2fd76543f88654a22489772cc9",
      "ba945f8d1aaa4c39bb6dfdf4ebd1752e",
      "74bad0e643bf4102a5d99d2c9a02e8a1",
      "c1818a879adc48c39b0961d37bc954c5",
      "304b69ce339147ea9a081151311acaf6",
      "e19febec2edf43fdaa32eb1fe62ca031",
      "8cd1819355d543b29baba590c8fe936d",
      "693d28d9becb40b296fab00bb475d1ce",
      "b0118c1ad9a64b70b6c123835fd1727d",
      "a390fb1e76304bc58bfcb65cf061c641",
      "05a80d8c55564dcbbbea46cbd03b3565",
      "49f59135871246299d57fb9b90ac4cd9",
      "b27902ee286345cc96a02280a00e52f8",
      "f8213655518e41499919eac7e018661b",
      "13e09cdd1e4d4aadb46a7fc6dade6e96",
      "bdcf72a2fd7e427eae9af34ef455bcca",
      "ae5beb6d0edc4458a643b5108ac3d65d",
      "c207f30dfe244bcc8b0e2a7c976562c7",
      "7a845a74a6ef4af19e691f57a05a48dd",
      "14c920e240fe4224aa902041f2e9da25",
      "8f89dff15f874025814c3298d274e15c",
      "745563f83d2648f78ce7d9a8f07bb774",
      "44f80b8612ab4c3bad575cc703e7f22a",
      "a9fdf321b0034161bb883940d300a679",
      "a0bbb2b5543549568d9e01bbc8c37364",
      "51cbfe8a0dbf44158380606620f7c35c",
      "4529d989589c488a95f97a2dce84e4f9",
      "9338eac972984a98965880be480f0896",
      "b7af83e1f71b41658995162727d20949",
      "d0f183f8c92d42c5819a6bb819fa83aa",
      "e9e30daa8e5949ac9004dff626b13d1c",
      "740aa9f576504264812036af28345ca2",
      "596714bcfb064c68ab57e01238b618c9",
      "277baec54880414eb7a48acd45ab2b3b",
      "0601617fcc2a4739a5e60c57f9bf61af",
      "521c6907bff848f09750f4895f70a120",
      "644fa671498e43b39040d1ac2063b093",
      "8de7c8ecf8084ebc936783c93d066309",
      "7178d0e110e749ddbaeaabca6acfbe17",
      "0c0d279678d44ffd84145cf481ca376f",
      "4d1d3fb4925041d1a474d6fc08ae9d8f",
      "bbcfb16af198458fb2853049a0a5d075",
      "ff25d73837384c6c8c2b1847c5845adf",
      "2b973b8f0f354ba98909f4c223c2d32f",
      "cf5c8ca0dd2e4ca08e2ab0dd4afa80b0",
      "6cec96d52a064defa7adbcea20abe102",
      "59e76254475748138a1b2505b23746ef",
      "8b1e856caa38424eba93aa329f1c3dec",
      "9da15d669eea461492adf508478e1c13",
      "b7a178bac5144b08857528a210478e74",
      "1b1f2519da344bc89a48b0e6669fd0bd",
      "0e2a2a752554453d9adf866b77bbc771",
      "4224cef9a21548d488f6b3f3e9340b27",
      "9a914140df234a8ab3df5d04f95061a5",
      "5dbd339b7c0a4c6b9c973ec0903bba7f",
      "5d3098f58ba34d4ebb6f711a2d5ac3a9",
      "7b8c913885744784922bcb14752dc7f2",
      "78bf1aace25f48b19f9d22f08fb65f26",
      "fc02aea2ac7348d1bc1f1515af6be430",
      "788acbe21e7f446097abc65fe8962ced",
      "271484e0d2674f23ad6bf382c0f7c830",
      "27f0b8abd8bc4923885900f34497d42e",
      "958a4764b80c4b81bda67077fbd9cf4f",
      "60160952794a4472aa84333a268d25dd",
      "bbc49a740bed4da992dd4d3a2dc3ffb2",
      "4f6ff69d439b434ca4714c8664778aea",
      "f3313a0a58c1492a8950c771b0faf3f7",
      "59216c933fcf418ab74fb2c0942e450b",
      "69f40e8c27484032a9532cf7542cc97c",
      "369a12554051445cb018acc3657cffa6",
      "7d3575826f49490fb012e4d589f506d3",
      "0b89486599184c58a0edbc2a693a2710",
      "beb373f63efa48b0b087b5c39fafe3c6",
      "a5427ebbde9d43aaa46782fabf5b54dc",
      "fd4b6ae450f74e49899107ac4de3709d",
      "17cb8179e1e6415e941529c6027addbb",
      "6030751791dd4b119e90274298d971e3",
      "7a058abf54f94266967a5474a054e0a5",
      "5ffacc7d6dba4b0c99c279e8ed75dbe9",
      "2728f8be896d4d0aae180f51c991cfd7",
      "853a04fe653b40c8ac2a0f4e16cfebb1",
      "af61c588b49c40c1a46f0c97d10bfc0b",
      "66748200566f400893b6d1adee74e572",
      "33140219e3de40ee960dc7425605aa88",
      "c35a17d99e4541cbad25a5357d709c43",
      "3a4cfdce146c42a9b149519513edd8cf",
      "91653cdd79a84f04bf4d87609ee6364e",
      "5cddcf7705a546779b18f0b8f6282547",
      "efd193fec8d8491b9eb2678709005a84",
      "c3e171d62c2548ba9dc939f245153c27",
      "cdd9ad90fb754d5597f6be66be254387",
      "8ec86d42e4834019baba9840f62343be",
      "19f29945492647b5a1ff87ccf0c7ff39",
      "231f4d581fe1498bbed7de337238847e",
      "7cb91f61ba6941218308017b385903f1",
      "10991e111b044c4081a3f63b9c2184d1",
      "a4dbab7093a942c1a3b9d4075442856f",
      "a572b11bf80d49a387c969da1c3908e9",
      "e551dd024a164e43b936973c9b7ecbae",
      "0629fb47935d41db80d0103a1e6b59b3",
      "5f91d976426b4962b18c265338f28a6b",
      "79ead93585894f7c9e5e6c912bd1eb24",
      "4c8d21162b704f9080b9234d5f533b53",
      "6ea31c19ca4142e5884af4f2f3b0b5f9",
      "9222ba0f077a438286e86d8f09b2e172",
      "8f8890b0d7a046e3b8d889362fb2fed4",
      "3b987aaa5f034732b64535d3d4869cc0",
      "90e36b5a95504fcda120a012f8f6cf08",
      "0f77338c52d0452da435825013ac072f",
      "7812e436a8ef42409bdb138ac28dde96",
      "202eee35cc3d4ddcad916cd919e28408",
      "6885fa5e06d546e68e66edae463eabc2",
      "fb0838a0191b4228ac05bbd192aa77d4",
      "19048f21770a41bea2db7827271bcd2d",
      "bd106660d2c842f58b9509ad3fd24c9c",
      "ab83978351724b3dafc26a64519c4361",
      "7d04bf57b55a4365af2c81e22ae43eef"
     ]
    },
    "id": "Opwjd0f515m3",
    "outputId": "badeb943-4033-4c89-f15b-f400ffcb3b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Artificial Intelligence is transforming the world.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1f67d6e126449f99b2512ebde648df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35485d2019e84e75b7d3f1c29eebd4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8442560da74575bed9e715da21403e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67a38341c95494d9b0a2af64b51d1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c88f89ce739143438323e0bb0565146d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b7a469845b44ff9fab1d0e86e613ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e7befac7b2479e84733805e0bbc809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.decoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
      "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.encoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693d28d9becb40b296fab00bb475d1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French: L'intelligence artificielle transforme le monde.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a845a74a6ef4af19e691f57a05a48dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f183f8c92d42c5819a6bb819fa83aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/768k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1d3fb4925041d1a474d6fc08ae9d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/797k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2a2a752554453d9adf866b77bbc771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958a4764b80c4b81bda67077fbd9cf4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5427ebbde9d43aaa46782fabf5b54dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/298M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35a17d99e4541cbad25a5357d709c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10991e111b044c4081a3f63b9c2184d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/298M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.decoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
      "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.encoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b987aaa5f034732b64535d3d4869cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German: K√ºnstliche Intelligenz verwandelt die Welt.\n"
     ]
    }
   ],
   "source": [
    "#q7\n",
    "# Install if not installed\n",
    "!pip install -q transformers sentencepiece sacremoses\n",
    "\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Define input text FIRST\n",
    "text = \"Artificial Intelligence is transforming the world.\"\n",
    "\n",
    "# Translation function\n",
    "def translate(text, model_name):\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "    translated = model.generate(**tokens)\n",
    "    return tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "\n",
    "# Translate\n",
    "print(\"Original:\", text)\n",
    "print(\"French:\", translate(text, \"Helsinki-NLP/opus-mt-en-fr\"))\n",
    "print(\"German:\", translate(text, \"Helsinki-NLP/opus-mt-en-de\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gcoLMs-J49sY"
   },
   "outputs": [],
   "source": [
    "#q8\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        return outputs, hidden\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hid_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hid_dim*2, hid_dim)\n",
    "        self.v = nn.Linear(hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = encoder_outputs.shape[0]\n",
    "        hidden = hidden.repeat(seq_len, 1, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        return torch.softmax(attention, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 970,
     "referenced_widgets": [
      "1e8837ab6c09491d98ddf3dc1010f349",
      "c2c9e0fb0007424d95be1e6318a7e8fa",
      "f2e0780ed0014411929733ab908c8e69",
      "b55fc77bfa4144fd9ad28a039a8549b4",
      "fa99341ac43941faa525ca8bc465ac4a",
      "4cc39638db844419a4fd5aabcf152b85",
      "ecbe5634f124459c9dc664441d87a3c7",
      "480a03ab18954a05b7ab13a4f4dd890f",
      "c03b4995405048ed8ffa005d5006823b",
      "3ae2aa74834444ec9e3e77289ff981ba",
      "052b21fbe2e44257a3c0afc5d478a598",
      "501d672262bd45e7bd948edab5e6668e",
      "a515341d39654c9aa368e379e7b51732",
      "254c85a5ea964fd3a7501fe30df0eb6e",
      "5b03fcfd45d347b48fde75b91f14ce79",
      "cccc9c7bb663417bb8eee5b367901676",
      "317b54e582964594849d783c9f9912ce",
      "2523fb90f00844deb0b41f0a52db528f",
      "ff3d4753553c4d03869c7753f924a56c",
      "eb82067e2cff4254ab7952e8812a49b8",
      "b79ea9bc8ee94bd39a66b6e874852ab2",
      "657cd2d66411417da8f009d15277414f",
      "892395d8f8e64b96b51ba6621506b91e",
      "9c89e46e2310445f941a495694bd76e5",
      "7059da1cdf0043e1b3ac647f11bfdd02",
      "a68b4b99d4b849999e90818f6a40acba",
      "f82b326cb4954e01a72cfee997f51477",
      "e0fcf7c3a4ca40ec94046a5ee359db73",
      "74d6a26fba824f7987a54c2e7f1d4dc7",
      "f53aa063d26d4fa4966b7426444c7bae",
      "39443152017d4bf29d250613e9c2f918",
      "89f6904b3df945a2a2669b47c419719e",
      "db2ab2781e7744d79d8d671d86ff7b48",
      "3c37589fe796476fb1b78da90850209f",
      "de997bf82b664dc08ee92637f377a58a",
      "038e1e6eeb4b43129df65f0bde177508",
      "01fc1fa40e0c4f98a89ed1e1d0c595a3",
      "2097df732d154f6aa76ae9eb631fde9b",
      "86cc72a244264804af6e06134b651700",
      "516f10ac6f104efeb666acd6c2c89ab8",
      "dbe764b2a90548a88314004bf96f92c2",
      "bfe11c069d2a48618965b12058e8b448",
      "6ad7bc3c98734d4c9bfc709822f3d122",
      "5c83d298bdb94acc83391859b400e10c",
      "bce3d264dd2d422688b1d89dc9208d4f",
      "64bcfdcd8a5f4b5fa8ad497dcf1a331f",
      "fa5c54c7c2db4763af107d9c394d9303",
      "0364608301c84eceb548272a13f8c6cf",
      "53b1298ad63a49519d748a2d5c09e166",
      "739f45dda56942b3ac555ab21f7bfe4e",
      "43d587f65ff3401aaa49a0bd1f9a397f",
      "644f4f4136a34e1cb84736a15ea4b0e5",
      "1f28e2891d3e4536a6043b018e0d8fd5",
      "96a723a51fa640759c32e259c6a2369f",
      "e34ff718d10541a0ae04ca63f8a3fc2b",
      "0193f66439ff491b9c9498385539c2b6",
      "2cbb526235b84926a62e02fccef3ef75",
      "cc926a71761b4308a6881c9e6c5fce8d",
      "d241fefbf8994911b9453772d15f5d94",
      "637c2773bc124de58a9587a7056b859f",
      "06ba6bdcb7a4494a92180834f1545088",
      "402c8a49c7784eb6bd51bbf2273ceeba",
      "2aaa4494291d4e14a092f132bc044eab",
      "f4f0247d63f24841abb57ded247057ec",
      "b3bc333fb65d4d3ab43ab6f48a68f15a",
      "f47e9047d724441983be2083d2dc1d2c",
      "101070ca38954db7b25577f250d18b74",
      "d1473812e37846128e1079b3bd252865",
      "64a345ff65e845df90f73302cd9e712e",
      "0a631d09637f485795a6038ec6b40dac",
      "9ab119065b754b3f86dc9e1785ad5f1b",
      "2e383688aae849f5996ecf8e717fc3fd",
      "5a4d92e73cc04404bfec12540aad6e89",
      "8e21ffbf16b14576b95fbbb88a7bde01",
      "f5a67a57383044ad8ab22f6ac1f5aa54",
      "fb7a3cf74d61418c9a7e2362ad676ab2",
      "4fa005e45c6e446a871102dfd98d5f0a",
      "b3c3d057b0af497391f27e59ed551077",
      "051467ea0d5a47ebaba6b74e528d859e",
      "22afb436200a47c3b95f3394640762d9",
      "5153b66ed9074392b33b6b8253968cb0",
      "fcf8eb9c78284ef6875042ce744e4e95",
      "158948bc883947058b424ffdbe796ef8",
      "c466d70a6fac455a8576db1f5e04ab29",
      "9fc02213848e40d993163ed82c9672c0",
      "0b588e2feef74a768c51e13633239e7a",
      "c061a6f3f62549cfbf94f51ebd4bfe15",
      "04dcb2749c03478aa9227bd0d1399b12"
     ]
    },
    "id": "xbB9dRC75T96",
    "outputId": "bbc2ca26-43fc-4151-a2c3-029a085c5b03"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8837ab6c09491d98ddf3dc1010f349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501d672262bd45e7bd948edab5e6668e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892395d8f8e64b96b51ba6621506b91e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel LOAD REPORT from: gpt2\n",
      "Key                  | Status     |  | \n",
      "---------------------+------------+--+-\n",
      "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c37589fe796476fb1b78da90850209f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce3d264dd2d422688b1d89dc9208d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0193f66439ff491b9c9498385539c2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101070ca38954db7b25577f250d18b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c3d057b0af497391f27e59ed551077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing `generation_config` together with generation-related arguments=({'num_return_sequences', 'max_length'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=40) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roses are red, violets are blue, and the heart is red.\n",
      "\n",
      "The blood vessels on the outside of the heart are thicker than on the inside.\n",
      "\n",
      "The heart's airways (myocardial and paracrine chambers) are smaller and have smaller, more flexible walls.\n",
      "\n",
      "The veins are thinner than on the outside, and have smaller, more flexible walls.\n",
      "\n",
      "The heart's blood vessels are much thinner than on the outside, and have thinner, less flexible walls.\n",
      "\n",
      "The heart's arteries are larger and have smaller, more flexible walls.\n",
      "\n",
      "The heart's blood vessels are larger and have larger, more flexible walls.\n",
      "\n",
      "The heart's blood vessels are smaller and have smaller, more flexible walls.\n",
      "\n",
      "The heart's blood vessels are larger and have larger, more flexible walls.\n",
      "\n",
      "The heart's blood vessels are larger and have larger, more flexible walls.\n",
      "\n",
      "The heart's blood vessels are smaller and have smaller, more flexible walls.\n",
      "\n",
      "The heart's blood vessels are smaller and have smaller, more flexible walls.\n",
      "\n",
      "The heart's blood vessels are smaller and have smaller, more flexible walls.\n",
      "\n",
      "The heart's blood vessels are smaller and have smaller, more flexible walls.\n",
      "\n",
      "The heart's blood vessels are smaller and have\n"
     ]
    }
   ],
   "source": [
    "#q9\n",
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "prompt = \"Roses are red, violets are blue,\"\n",
    "poem = generator(prompt, max_length=40, num_return_sequences=1)\n",
    "\n",
    "print(poem[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a9d351ccedc94cbd8b3680c0271afdee",
      "bfb80b1d63a24e5c8be257b0591cfde9",
      "fc1ade1e899442b1878d68cab1362443",
      "8bab29066c40425794a3587fe07e41bd",
      "06d49cd2a7aa403992d93e4e4e2befa0",
      "d3c4625eeb1046e3a1c5d53721aafca7",
      "a37a71cfc6fe4db998c942f64d24441d",
      "e40bcd421c8842b6b8a97ca31816c20f",
      "865cf3868a074bf997f71928dc4ad59a",
      "41da056dced44a62a5ccafcf66a685ad",
      "48e4aa3ea5b146ecb8a4ba7ee2a02931",
      "5675eab28e054a6080801886b15abece",
      "c158043a494040af9ec2f024f0dde689",
      "6dcb66eb8c974c7ab62ce97addd908b0",
      "9f0fee855b72438db086e21929bc5670",
      "400260dcdf824cb99cba4c687376f1eb",
      "57f7b5d1490a4cc4a3b7f9ca7a8ad52f",
      "6ae47927a4924f6ba2e2605b1a1f5231",
      "efbb066d953a444ebccedf83cc532f3d",
      "403c149232e14565b826bcbd4caf5cdf",
      "74f0053dba344ae2b88390f68dd61b5c",
      "2215ff5b468449d4a8be595d27d6249a",
      "f93814e8124e4635a70be9873266f084",
      "4d6ed550179f4f4eb5ed5fa2a56e5296",
      "ea025188ff004cea841ebcbde49d57c2",
      "d497abbde3b64c429fc72a61a2442a11",
      "d076e3ba607441fd9c83040fa9cfcba2",
      "7dc85a6975364a94beb370596457bcb7",
      "90fb9bcf69954f1d9e64e696bcdac3d9",
      "d0e80a13e71d42ac88ff759be194afd2",
      "df282176bd84468c9b449a2b724d9c0c",
      "5d0fc7acf71140cea2217282504eb8a1",
      "23d0108abfb74629bfc10a35c64ba092",
      "e4873936ceb0496dbbeb2605c605e817",
      "6cee3f53d2b44870a2ecb16181f84611",
      "dcc17476a40349b4bde16aa23bf86198",
      "050f3f0d32174ae694617d514d449604",
      "5ee8fa65309541cdbbe7246e15c13a82",
      "a9315bc2b66c4f5583512a93f020d435",
      "45b1fa13eef749efb3c77c62099e400e",
      "3223a40c214049969593885d286c5c66",
      "92dae6449b974285beabeb6f1977b85d",
      "8d416fc74ec542feb305dd50be84bbaa",
      "be63cc15589543379030bb43a65cd528",
      "6449f57809104ada86cb6637c1fb8fe8",
      "a246b8ef71e84596bc5d6aed9b50a290",
      "69e9f68292644488b508e6639c97007b",
      "ae2b0c5d18474a0b811f2361a0319592",
      "1e4181f0e20b433cab6f5f11a62b3c25",
      "db197d2241ae466db9b1b15f9c71059e",
      "c9688d6db674437e9fa96ab99e14fc3f",
      "40498b29152f45c9b7d9e51c3016f390",
      "0fba4e49a4874e9fb934ed8ee55b5697",
      "6f1c609f33344b48901ec582f14461b5",
      "36f42e2493d0442c93a62578e23d0ce9",
      "c8b1019758a44392a2f512396d8d070d",
      "a7ce90683fdc4704a9144a72ded11035",
      "54edb1dde2244023b54e025c807eb037",
      "1fa8e49f878f4290bd97b1841aaa87a0",
      "306363de50d34fb1bc617ece4bf5d8ac",
      "665c811bc1524466b5e4a47d95f73be4",
      "f60d93368e054412b77cdca6d1255b1c",
      "2d707eb7c50a45408530bf511e50b5ea",
      "8e3c04756d7241c69055eca2703cb79f",
      "985e8f5556524c55bf642edefb00c87a",
      "ee25f61d16f64099bebf039bfd870c46",
      "7e4368d55897494f8718f56acacf16e2",
      "6a00c929ac4c49e9a275eeb419a8cba7",
      "de333d8c30d94eb8a0837e4ca9e33728",
      "171de6a5d0d9487eb0632546e638f9b0",
      "efcd4cdff9c041ea93e5c529ace4bf46",
      "2d6e9fe9cd494c83b87623ebece29a9e",
      "a6787ec358814eaa89dc498d96136eac",
      "c2a5e91705fc436ebf67886376c5490f",
      "836f7b57b5254b75bf3395c164427251",
      "bbcbacaa1ba9463bbd6bd60020fdc8a1",
      "1f794ed47c4c49b48540b98e3270e258"
     ]
    },
    "id": "v66_d8m25oso",
    "outputId": "eaff4722-cfa0-4239-ad77-f86823afc8aa"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d351ccedc94cbd8b3680c0271afdee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5675eab28e054a6080801886b15abece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tied weights mapping and config for this model specifies to tie shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93814e8124e4635a70be9873266f084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4873936ceb0496dbbeb2605c605e817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6449f57809104ada86cb6637c1fb8fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b1019758a44392a2f512396d8d070d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4368d55897494f8718f56acacf16e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'T5ForConditionalGeneration' is not supported for text-generation. Supported models are ['PeftModelForCausalLM', 'AfmoeForCausalLM', 'ApertusForCausalLM', 'ArceeForCausalLM', 'AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BitNetForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'BltForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'CwmForCausalLM', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV2ForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'DogeForCausalLM', 'Dots1ForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'Ernie4_5ForCausalLM', 'Ernie4_5_MoeForCausalLM', 'Exaone4ForCausalLM', 'FalconForCausalLM', 'FalconH1ForCausalLM', 'FalconMambaForCausalLM', 'FlexOlmoForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'Gemma3nForConditionalGeneration', 'Gemma3nForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'Glm4MoeForCausalLM', 'Glm4MoeLiteForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GptOssForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeHybridForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'HunYuanDenseV1ForCausalLM', 'HunYuanMoEV1ForCausalLM', 'Jais2ForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'Lfm2ForCausalLM', 'Lfm2MoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'LongcatFlashForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegatronBertForCausalLM', 'MiniMaxForCausalLM', 'MiniMaxM2ForCausalLM', 'MinistralForCausalLM', 'Ministral3ForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'ModernBertDecoderForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NanoChatForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'Olmo3ForCausalLM', 'OlmoeForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'Qwen3NextForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'SeedOssForCausalLM', 'SmolLM3ForCausalLM', 'SolarOpenForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TrOCRForCausalLM', 'VaultGemmaForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'xLSTMForCausalLM', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n",
      "Passing `generation_config` together with generation-related arguments=({'max_new_tokens', 'temperature', 'do_sample'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n",
      "Both `max_new_tokens` (=200) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=200) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "  CREATIVE WRITING ASSISTANT  \n",
      "==============================\n",
      "\n",
      "üéØ GENERATED STORY PLOT:\n",
      "\n",
      "\n",
      "Write a detailed creative story plot.\n",
      "\n",
      "Genre: Fantasy\n",
      "Theme: A hidden kingdom beneath the ocean\n",
      "\n",
      "Include:\n",
      "- Main conflict\n",
      "- Setting\n",
      "- Unique twist\n",
      "- Ending hook\n",
      "oard Sunderbrook Reef off Oregon near Panama. Surborn, by his second childhood father Jack Dolph Whitemoor with little education available is forced the expedition starts its journey that would only find rich potential into world economy due on all points; at such great incipense height level to begin World Empire but little before falling victim\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "üë§ GENERATED CHARACTER DESCRIPTION:\n",
      "\n",
      "\n",
      "Create a main character for a Fantasy novel.\n",
      "\n",
      "Include:\n",
      "- Name\n",
      "- Age\n",
      "- Personality\n",
      "- Background\n",
      "- Strength\n",
      "- Weakness\n",
      "er by raising two children while there lives stay dead so noone, or as alloran, comes through an act to detestes that have now returned which now has happened so to those toyin. These three youngsters seem unaware they had just done away during these adventures they see the monster and kill his brother who infest is no sign either...he and one daughter decide only about 10 minwer will turn as this is yet only day-in...its will give mighty little gain due all too soon when both new things will dawn! Until later with one baby who had grown all excited just waiting up at Kingryndestark the house at Sturbachth of Thedye canaston has an unplanned hover off on Kingrington Stair the family comes upon Queen Shen\n",
      "\n",
      "==============================\n",
      "Generation Complete ‚úÖ\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# Q10 - Creative Writing Assistant\n",
    "\n",
    "# =========================================\n",
    "\n",
    "# Install transformers (safe version)\n",
    "!pip install -q transformers sentencepiece\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Use text-generation instead of text2text-generation\n",
    "generator = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=\"google/flan-t5-base\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# USER INPUT\n",
    "# -----------------------------\n",
    "genre = \"Fantasy\"\n",
    "theme = \"A hidden kingdom beneath the ocean\"\n",
    "\n",
    "# -----------------------------\n",
    "# STORY PLOT PROMPT\n",
    "# -----------------------------\n",
    "plot_prompt = f\"\"\"\n",
    "Write a detailed creative story plot.\n",
    "\n",
    "Genre: {genre}\n",
    "Theme: {theme}\n",
    "\n",
    "Include:\n",
    "- Main conflict\n",
    "- Setting\n",
    "- Unique twist\n",
    "- Ending hook\n",
    "\"\"\"\n",
    "\n",
    "# Generate story plot\n",
    "plot_output = generator(\n",
    "    plot_prompt,\n",
    "    max_new_tokens=200,\n",
    "    temperature=0.9,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# CHARACTER PROMPT\n",
    "# -----------------------------\n",
    "character_prompt = f\"\"\"\n",
    "Create a main character for a {genre} novel.\n",
    "\n",
    "Include:\n",
    "- Name\n",
    "- Age\n",
    "- Personality\n",
    "- Background\n",
    "- Strength\n",
    "- Weakness\n",
    "\"\"\"\n",
    "\n",
    "# Generate character\n",
    "character_output = generator(\n",
    "    character_prompt,\n",
    "    max_new_tokens=200,\n",
    "    temperature=0.9,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# DISPLAY RESULTS\n",
    "# -----------------------------\n",
    "print(\"\\n==============================\")\n",
    "print(\"  CREATIVE WRITING ASSISTANT  \")\n",
    "print(\"==============================\\n\")\n",
    "\n",
    "print(\"üéØ GENERATED STORY PLOT:\\n\")\n",
    "print(plot_output[0][\"generated_text\"])\n",
    "\n",
    "print(\"\\n---------------------------------\\n\")\n",
    "\n",
    "print(\"üë§ GENERATED CHARACTER DESCRIPTION:\\n\")\n",
    "print(character_output[0][\"generated_text\"])\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"Generation Complete ‚úÖ\")\n",
    "print(\"==============================\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
